{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 04\n",
        "author:\n",
        "  - name: JulioVargas\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2025-10-07'\n",
        "date-modified: today\n",
        "date-format: long\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "\n",
        "execute:\n",
        "  echo: false\n",
        "  eval: false\n",
        "  freeze: auto\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the Dataset (1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Using incubator modules: jdk.incubator.vector\n",
            "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/10/08 14:54:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/10/08 14:55:08 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n",
            "|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n",
            "|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n",
            "|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n",
            "|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 3:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook+notebook_connected+vscode\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"data/lightcast_job_postings.csv\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)\n",
        "print(df.count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/vnd.holoviews_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.holoviews_exec.v0+json": "",
            "text/html": [
              "<div id='ea86f1e0-07cf-41b9-ae3c-8761a0d924bb'>\n",
              "  <div id=\"d85d7076-e727-41b0-8165-fa49c6e1058d\" data-root-id=\"ea86f1e0-07cf-41b9-ae3c-8761a0d924bb\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"bf37ec1a-c847-4a02-b902-d901b1d16721\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"ea86f1e0-07cf-41b9-ae3c-8761a0d924bb\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"68b4b6db-0cf4-414d-91e8-e55f4f6fb557\",\"attributes\":{\"plot_id\":\"ea86f1e0-07cf-41b9-ae3c-8761a0d924bb\",\"comm_id\":\"746b7095ed3e41aa83624e6ff8e77004\",\"client_comm_id\":\"d19466ef8a464df7b84fa4420b055e40\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"bf37ec1a-c847-4a02-b902-d901b1d16721\",\"roots\":{\"ea86f1e0-07cf-41b9-ae3c-8761a0d924bb\":\"d85d7076-e727-41b0-8165-fa49c6e1058d\"},\"root_ids\":[\"ea86f1e0-07cf-41b9-ae3c-8761a0d924bb\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  async function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t  for (const child of root_el.children) {\n",
              "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
              "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
              "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ]
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "ea86f1e0-07cf-41b9-ae3c-8761a0d924bb"
            }
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+--------------------+--------+-------------------+-------------+----------+----------------+----------------------+-------------------+------------------+\n",
            "|SALARY|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|DURATION|COMPANY_IS_STAFFING|IS_INTERNSHIP|STATE_NAME|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME  |MIN_EDULEVELS_NAME |MAX_EDULEVELS_NAME|\n",
            "+------+--------------------+--------------------+--------+-------------------+-------------+----------+----------------+----------------------+-------------------+------------------+\n",
            "|NULL  |2                   |2                   |6       |false              |false        |Arkansas  |[None]          |Full-time (> 32 hours)|Bachelor's degree  |NULL              |\n",
            "|NULL  |3                   |3                   |NULL    |true               |false        |Maine     |Remote          |Full-time (> 32 hours)|No Education Listed|NULL              |\n",
            "|NULL  |5                   |NULL                |35      |false              |false        |Texas     |[None]          |Full-time (> 32 hours)|Bachelor's degree  |NULL              |\n",
            "|NULL  |3                   |NULL                |48      |false              |false        |Arizona   |[None]          |Full-time (> 32 hours)|No Education Listed|NULL              |\n",
            "|92500 |NULL                |NULL                |15      |false              |false        |California|[None]          |Part-time / full-time |No Education Listed|NULL              |\n",
            "+------+--------------------+--------------------+--------+-------------------+-------------+----------+----------------+----------------------+-------------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        index              column  is_missing\n",
            "0           0              SALARY        True\n",
            "1           1              SALARY        True\n",
            "2           2              SALARY        True\n",
            "3           3              SALARY        True\n",
            "4           4              SALARY       False\n",
            "...       ...                 ...         ...\n",
            "797473  72493  MAX_EDULEVELS_NAME        True\n",
            "797474  72494  MAX_EDULEVELS_NAME        True\n",
            "797475  72495  MAX_EDULEVELS_NAME        True\n",
            "797476  72496  MAX_EDULEVELS_NAME        True\n",
            "797477  72497  MAX_EDULEVELS_NAME        True\n",
            "\n",
            "[797478 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, pow\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from pyspark.sql.functions import col, sum as spark_sum, when, trim, length\n",
        "import hvplot.pandas  # enables hvplot on pandas\n",
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "eda_cols = [\n",
        "    \"SALARY\",\n",
        "    \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \"DURATION\",\n",
        "    \"COMPANY_IS_STAFFING\", \"IS_INTERNSHIP\",\n",
        "    \"STATE_NAME\", \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\",\n",
        "    \"MIN_EDULEVELS_NAME\", \"MAX_EDULEVELS_NAME\"\n",
        "]\n",
        "\n",
        "df_eda = df.select(eda_cols)\n",
        "df_eda.show(5, truncate=False)\n",
        "\n",
        "df_eda = df_eda.withColumn(\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-Premise\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-Premise\")\n",
        "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "# 0. Heatmap Before missing value treatment\n",
        "df_eda = df_eda.toPandas()\n",
        "\n",
        "# create new DataFrame where each cell missing (True) or not (False)\n",
        "missing_mask = df_eda.isnull()\n",
        "\n",
        "# Melt into long-form  | 4 columns: index, column, is_missing\n",
        "missing_long = (\n",
        "    missing_mask.reset_index()\n",
        "    .melt(id_vars=\"index\", var_name=\"column\", value_name=\"is_missing\")\n",
        ")\n",
        "\n",
        "\n",
        "print(missing_long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chose Data (2.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Chose Categorial Columns and continuous \n",
        "# Dependent (y): SALARY\n",
        "# Independent  (X):\n",
        "# Four numerical/boolean features:\n",
        "#   MIN_YEARS_EXPERIENCE, DURATION, IS_INTERNSHIP, COMPANY_IS_STAFFING\n",
        "# Two categorical features:\n",
        "#   REMOTE_TYPE_NAME, EMPLOYMENT_TYPE_NAME\n",
        "\n",
        "\n",
        "eda_cols = [\n",
        "    \"SALARY\",\n",
        "    \"MIN_YEARS_EXPERIENCE\", \"DURATION\",\n",
        "    \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\",\n",
        "    \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\"\n",
        "]\n",
        "\n",
        "df_eda = df.select(eda_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missing Value Treatment (2.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, when, isnan, count\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.functions import col, when, isnan, count, expr, median\n",
        "from pyspark.sql import functions as F\n",
        "#Cleaning - two categorical features\n",
        "\n",
        "df_eda = df_eda.withColumn(\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"[None]\", \"Undefined\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On-Premise\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\").isNull(), \"On-Premise\")\n",
        "    .otherwise(col(\"REMOTE_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "df_eda = df_eda.withColumn(\n",
        "    \"EMPLOYMENT_TYPE_NAME\",\n",
        "    when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time / full-time\", \"Flexible\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Part-time (â‰¤ 32 hours)\", \"Parttime\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\") == \"Full-time (> 32 hours)\", \"Fulltime\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Fulltime\")\n",
        "    .otherwise(col(\"EMPLOYMENT_TYPE_NAME\"))\n",
        ")\n",
        "\n",
        "#Cleaning Booleans -  IS_INTERNSHIP, COMPANY_IS_STAFFING\n",
        "df_eda = df_eda.withColumn(\"IS_INTERNSHIP\", when(col(\"IS_INTERNSHIP\").isNull(), False).otherwise(col(\"IS_INTERNSHIP\")))\n",
        "\n",
        "df_eda = df_eda.withColumn( \"COMPANY_IS_STAFFING\",when(col(\"COMPANY_IS_STAFFING\").isNull(), False).otherwise(col(\"COMPANY_IS_STAFFING\")) )\n",
        "\n",
        "#Cleaning Numericals with median in nulls - DURATION\n",
        "\n",
        "median_duration = df_eda.approxQuantile(\"DURATION\", [0.5], 0.01)[0]\n",
        "\n",
        "df_eda = df_eda.withColumn(\"DURATION\",\n",
        "                            when(col(\"DURATION\").isNull(), median_duration)\n",
        "                            .otherwise(col(\"DURATION\"))\n",
        "                        )\n",
        "\n",
        "#Cleaning Dependent (y) with median by : SALARY\n",
        "\n",
        "#overall median\n",
        "overall_median_salary = df_eda.approxQuantile(\"SALARY\", [0.5], 0.01)[0]\n",
        "\n",
        "# median by EMPLOYMENT_TYPE_NAME\n",
        "median_by_employment_type_name = df_eda.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(\n",
        "    expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_emp_type_name\")\n",
        ")\n",
        "\n",
        "# Join median values back to the original dataframe\n",
        "df_salary_imputed = df_eda.join(median_by_employment_type_name, on=\"EMPLOYMENT_TYPE_NAME\", how=\"left\")\n",
        "\n",
        "# Replace missing SALARY values\n",
        "df_eda_clean = df_salary_imputed.withColumn(\"SALARY\", when(col(\"SALARY\").isNull(),\n",
        "    when(col(\"median_salary_emp_type_name\").isNotNull(), col(\"median_salary_emp_type_name\"))\n",
        "    .otherwise(overall_median_salary)\n",
        ").otherwise(col(\"SALARY\")))\n",
        "\n",
        "# Verifying in Excel\n",
        "#df_eda_clean_pd = df_eda_clean.toPandas()\n",
        "#df_eda_clean_pd.to_excel(\"df_eda_clean.xlsx\", index=False, engine=\"openpyxl\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop rows with missing values (2.2.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop rows with NA values in relevant columns\n",
        "# eda_cols = [\n",
        "#     \"SALARY\",\n",
        "#     \"MIN_YEARS_EXPERIENCE\", \"DURATION\",\n",
        "#     \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\",\n",
        "#     \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\"\n",
        "# ]\n",
        "from pyspark.sql.types import BooleanType, StringType, IntegerType\n",
        "from pyspark.sql.types import IntegerType,DoubleType,DecimalType\n",
        "\n",
        "\n",
        "regression_df = df_eda.dropna(subset=eda_cols)\n",
        "\n",
        "#Convert categorical/boolean columns to numeric types to avoid errors in Assembler, pipeline ...\n",
        "regression_df=regression_df.withColumn(\"IS_INTERNSHIP\", col(\"IS_INTERNSHIP\").cast(IntegerType()))\n",
        "regression_df=regression_df.withColumn(\"COMPANY_IS_STAFFING\", col(\"COMPANY_IS_STAFFING\").cast(IntegerType()))\n",
        "regression_df = regression_df.withColumn(\"DURATION\", col(\"DURATION\").cast(IntegerType()))\n",
        "\n",
        "# Verifying in Excel\n",
        "# regression_df = regression_df.toPandas()\n",
        "# regression_df.to_excel(\"df_eda_clean.xlsx\", index=False, engine=\"openpyxl\")\n",
        "\n",
        "#regression_df.schema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert, Assemble, Split, Pipeline (2.3 - 2.6)\n",
        "- Convert categorical variables into numerical representations using StringIndexer and OneHotEncoder.\n",
        "- Assemble features into a single vector using VectorAssembler.\n",
        "- Split the data into training and testing sets.\n",
        "- You can use pipeline to do the above steps in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23697, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18966, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4731, 12)\n",
            "+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n",
            "|SALARY|MIN_YEARS_EXPERIENCE|DURATION|IS_INTERNSHIP|COMPANY_IS_STAFFING|REMOTE_TYPE_NAME|EMPLOYMENT_TYPE_NAME|EMPLOYMENT_TYPE_NAME_idx|REMOTE_TYPE_NAME_idx|EMPLOYMENT_TYPE_NAME_vec|REMOTE_TYPE_NAME_vec|features                       |\n",
            "+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n",
            "|92962 |2                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n",
            "|107645|10                  |18      |0            |0                  |On-Premise      |Fulltime            |0.0                     |3.0                 |(2,[0],[1.0])           |(3,[],[])           |(7,[0,1,2],[10.0,18.0,1.0])    |\n",
            "|192800|6                   |55      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |\n",
            "|125900|12                  |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|\n",
            "|170000|6                   |18      |0            |0                  |Undefined       |Fulltime            |0.0                     |0.0                 |(2,[0],[1.0])           |(3,[0],[1.0])       |[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |\n",
            "+------+--------------------+--------+-------------+-------------------+----------------+--------------------+------------------------+--------------------+------------------------+--------------------+-------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "#| eval: true\n",
        "#| echo: false\n",
        "#| fig-align: center\n",
        "\n",
        "# 2.3 to 2.6 Convert, Assemble, Split, Pipeline\n",
        "# Categorical columns\n",
        "categorical_cols = [\"EMPLOYMENT_TYPE_NAME\", \"REMOTE_TYPE_NAME\"]\n",
        "\n",
        "# Index and One-Hot Encode\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid='skip') for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n",
        "\n",
        "# Assemble base features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"MIN_YEARS_EXPERIENCE\", \"DURATION\"\n",
        "    ] + [f\"{col}_vec\" for col in categorical_cols],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Create Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "regression_data = pipeline.fit(regression_df).transform(regression_df)\n",
        "\n",
        "\n",
        "# Split Data\n",
        "regression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\n",
        "print((regression_data.count(), len(regression_data.columns)))\n",
        "print((regression_train.count(), len(regression_train.columns)))\n",
        "print((regression_test.count(), len(regression_test.columns)))\n",
        "\n",
        "regression_data.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Create a new column MIN_YEARS_EXPERIENCE_SQ by squaring the MIN_YEARS_EXPERIENCE column.\n",
        "- Assemble the polynomial features into a new vector column features_poly using VectorAssembler.\n",
        "- Show the final structure of the DataFrame with the new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------------------------+------------------------------------------+\n",
            "|SALARY|features                       |features_poly                             |\n",
            "+------+-------------------------------+------------------------------------------+\n",
            "|92962 |[2.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[2.0,4.0,18.0,1.0,1.0])   |\n",
            "|107645|(7,[0,1,2],[10.0,18.0,1.0])    |(10,[0,1,2,5],[10.0,100.0,18.0,1.0])      |\n",
            "|192800|[6.0,55.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,55.0,1.0,1.0])  |\n",
            "|125900|[12.0,18.0,1.0,0.0,1.0,0.0,0.0]|(10,[0,1,2,5,7],[12.0,144.0,18.0,1.0,1.0])|\n",
            "|170000|[6.0,18.0,1.0,0.0,1.0,0.0,0.0] |(10,[0,1,2,5,7],[6.0,36.0,18.0,1.0,1.0])  |\n",
            "+------+-------------------------------+------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# Create squared term for Polynomial Regression\n",
        "regression_data_poly = regression_data.withColumn(\"MIN_YEARS_EXPERIENCE_SQ\", pow(col(\"MIN_YEARS_EXPERIENCE\"), 2))\n",
        "\n",
        "# Assemble polynomial features\n",
        "assembler_poly = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"MIN_YEARS_EXPERIENCE\", \"MIN_YEARS_EXPERIENCE_SQ\",\n",
        "        \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"\n",
        "    ] + [f\"{col}_vec\" for col in categorical_cols],\n",
        "    outputCol=\"features_poly\"\n",
        ")\n",
        "\n",
        "regression_data_poly_final=assembler_poly.transform(regression_data_poly)\n",
        "#show final structure\n",
        "regression_data_poly_final.select(\"SALARY\", \"features\", \"features_poly\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Test Split (3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23697, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18966, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 39:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4731, 12)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Split Data\n",
        "regression_train, regression_test = regression_data.randomSplit([0.8, 0.2], seed=42)\n",
        "print((regression_data.count(), len(regression_data.columns)))\n",
        "print((regression_train.count(), len(regression_train.columns)))\n",
        "print((regression_test.count(), len(regression_test.columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression (4)\n",
        "- Train a **Linear Regression** model using the training data.  \n",
        "  This model is from Lab 5.2 with three more added features.  \n",
        "- Make sure to use the **features** column from the assembled DataFrame to fit the model.  \n",
        "- You will run into an important issue here. Please make an effort in figuring it out by yourself.  \n",
        "  This is one of the most asked interview questions in CapitalOne's management recruiting program.  \n",
        "- Evaluate the model on the test data.  \n",
        "- Print the coefficients, intercept, **R²**, **RMSE**, and **MAE**.  \n",
        "- Use the **summary** object to extract the coefficients and their standard errors, t-values, and p-values.  \n",
        "- Create a DataFrame to display the coefficients, standard errors, t-values, p-values, and confidence intervals.  \n",
        "- Interpret the coefficients and their significance, and explain the model performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25/10/08 14:56:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
            "25/10/08 14:56:30 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
            "[Stage 43:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 75142.6520\n",
            "Coefficients:\n",
            " Feature 1: 6629.0352\n",
            " Feature 2: -89.0893\n",
            " Feature 3: 758.1210\n",
            " Feature 4: -6686.4509\n",
            " Feature 5: 10858.3452\n",
            " Feature 6: 13681.8588\n",
            " Feature 7: 18835.8525\n",
            "\n",
            "--- Regression Summary ---\n",
            "Coefficient Standard Errors: ['81.3631', '23.5386', '2051.7917', '2611.3277', '2048.9189', '2105.9892', '2544.8043', '2786.7053']\n",
            "T Values: ['81.4747', '-3.7848', '0.3695', '-2.5606', '5.2995', '6.4966', '7.4017', '26.9647']\n",
            "P Values: ['0.0000', '0.0002', '0.7118', '0.0105', '0.0000', '0.0000', '0.0000', '0.0000']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression \n",
        "from pyspark.ml.regression import LinearRegression\n",
        "feature_names = assembler.getInputCols()\n",
        "# featuresCol=\"features\" → the vector with all your input variables.\n",
        "# labelCol=\"SALARY\" → the target variable to predict.\n",
        "# family=\"gaussian\" normal distribution\n",
        "# maxIter=10 → number of iterations for least squares\n",
        "# regParam=0.3 → regularization parameter (L2 regularization by default)\n",
        "\n",
        "lr  = LinearRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"SALARY\",\n",
        "    #family=\"gaussian\", \n",
        "    #link=\"identity\", \n",
        "    maxIter=10, \n",
        "    regParam=0.3 \n",
        ")\n",
        "\n",
        "# Train the GLR model using the training dataset to learn the relationship between features and SALARY\n",
        "lr_model = lr.fit(regression_train)\n",
        "summary = lr_model.summary\n",
        "\n",
        "\n",
        "# Coefficients and Intercept\n",
        "print(\"Intercept: {:.4f}\".format(lr_model.intercept))\n",
        "print(\"Coefficients:\")\n",
        "for i, coef in enumerate(lr_model.coefficients):\n",
        "    print(f\" Feature {i + 1}: {coef:.4f}\")\n",
        "\n",
        "# Summary stats\n",
        "print(\"\\n--- Regression Summary ---\")\n",
        "print(\"Coefficient Standard Errors:\", [f\"{val:.4f}\" for val in summary.coefficientStandardErrors])\n",
        "print(\"T Values:\", [f\"{val:.4f}\" for val in summary.tValues])\n",
        "print(\"P Values:\", [f\"{val:.4f}\" for val in summary.pValues])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R²: 0.2630\n",
            "RMSE: 37295.1017\n",
            "MAE: 28914.9155\n",
            "---This is Diagnostic check, No need to print it in the final doc---\n",
            "Length of features: 8\n",
            "Length of coefs: 8\n",
            "Length of se: 8\n",
            "Length of tvals: 8\n",
            "Length of pvals: 8\n"
          ]
        }
      ],
      "source": [
        "# print(f\"\\nDispersion: {summary.dispersion:.4f}\")\n",
        "print(f\"R²: {summary.r2:.4f}\")\n",
        "print(f\"RMSE: {summary.rootMeanSquaredError:.4f}\")\n",
        "print(f\"MAE: {summary.meanAbsoluteError:.4f}\")\n",
        "#print(f\"Residual DF: {summary.residualDegreeOfFreedom}\")\n",
        "#print(f\"AIC: {summary.aic:.4f}\")\n",
        "\n",
        "# 1. Pull feature names directly from Java backend\n",
        "#feature_names = summary._call_java(\"featureNames\")\n",
        "\n",
        "# Get feature names safely\n",
        "num_coefs = len(lr_model.coefficients)\n",
        "feature_names = [f\"Feature_{i+1}\" for i in range(num_coefs)]\n",
        "\n",
        "\n",
        "# 2. Construct full table including intercept\n",
        "features = [\"Intercept\"] + feature_names\n",
        "coefs = [lr_model.intercept] + list(lr_model.coefficients)\n",
        "se =   list(summary.coefficientStandardErrors)  # add None for intercept\n",
        "tvals =   list(summary.tValues)\n",
        "pvals =   list(summary.pValues)\n",
        "\n",
        "# Diagnostic check\n",
        "print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "print(\"Length of features:\", len(features))\n",
        "print(\"Length of coefs:\", len(coefs))\n",
        "print(\"Length of se:\", len(se))\n",
        "print(\"Length of tvals:\", len(tvals))\n",
        "print(\"Length of pvals:\", len(pvals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Estimate</th>\n",
              "      <th>Std Error</th>\n",
              "      <th>t-stat</th>\n",
              "      <th>p-Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intercept</td>\n",
              "      <td>75142.6520</td>\n",
              "      <td>81.3631</td>\n",
              "      <td>81.4747</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feature_1</td>\n",
              "      <td>6629.0352</td>\n",
              "      <td>23.5386</td>\n",
              "      <td>-3.7848</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Feature_2</td>\n",
              "      <td>-89.0893</td>\n",
              "      <td>2051.7917</td>\n",
              "      <td>0.3695</td>\n",
              "      <td>0.7118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feature_3</td>\n",
              "      <td>758.1210</td>\n",
              "      <td>2611.3277</td>\n",
              "      <td>-2.5606</td>\n",
              "      <td>0.0105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Feature_4</td>\n",
              "      <td>-6686.4509</td>\n",
              "      <td>2048.9189</td>\n",
              "      <td>5.2995</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Feature_5</td>\n",
              "      <td>10858.3452</td>\n",
              "      <td>2105.9892</td>\n",
              "      <td>6.4966</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Feature_6</td>\n",
              "      <td>13681.8588</td>\n",
              "      <td>2544.8043</td>\n",
              "      <td>7.4017</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Feature_7</td>\n",
              "      <td>18835.8525</td>\n",
              "      <td>2786.7053</td>\n",
              "      <td>26.9647</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Build coefficient summary table\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Estimate\": [f\"{v:.4f}\" if v is not None else None for v in coefs],\n",
        "    \"Std Error\": [f\"{v:.4f}\" if v is not None else None for v in se],\n",
        "    \"t-stat\": [f\"{v:.4f}\" if v is not None else None for v in tvals],\n",
        "    \"p-Value\": [f\"{v:.4f}\" if v is not None else None for v in pvals]\n",
        "})\n",
        "\n",
        "# 4. Save for report\n",
        "coef_table.to_csv(\"output/lr_summary.csv\", index=False)\n",
        "\n",
        "# 5. Optional pretty print\n",
        "HTML(coef_table.to_html())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Regression Conclusion (4)\n",
        "The model explains about 26% of the salary changes (R2 = 0.26). That’s a bit low, so the model works but not very well yet.\n",
        "\n",
        "The errors (RMSE (37K) and MAE  (29K)) are quite high, which means the predictions are not very accurate. It could improve with more or cleaner features.\n",
        "\n",
        "Most features are important (p < 0.05), but Feature_2 (p = 0.71) doesn’t really affect salary.\n",
        "\n",
        "The intercept (75K) is the base salary when everything else is zero.\n",
        "\n",
        "Some coefficients are negative even when that doesn’t make much sense, so the model is not fitting perfectly. Positive ones (like Feature_5, Feature_6, and Feature_7) increase salary, and negative ones (like Feature_4) decrease it.\n",
        "\n",
        "In short, the model gives a general idea, but it’s not fine-tuned yet and needs improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Generalized Linear Regression Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 75142.6520\n",
            "Coefficients:\n",
            " Feature 1: 6629.0352\n",
            " Feature 2: -89.0893\n",
            " Feature 3: 758.1210\n",
            " Feature 4: -6686.4509\n",
            " Feature 5: 10858.3452\n",
            " Feature 6: 13681.8588\n",
            " Feature 7: 18835.8525\n",
            "\n",
            "--- Regression Summary ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficient Standard Errors: ['81.3631', '23.5386', '2051.7917', '2611.3277', '2048.9189', '2105.9892', '2544.8043', '2786.7053']\n",
            "T Values: ['81.4747', '-3.7848', '0.3695', '-2.5606', '5.2995', '6.4966', '7.4017', '26.9647']\n",
            "P Values: ['0.0000', '0.0002', '0.7118', '0.0105', '0.0000', '0.0000', '0.0000', '0.0000']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null Deviance: 35794690345776.1094\n",
            "Residual DF Null: 18965\n",
            "Deviance: 26380276237620.0078\n",
            "Residual DF: 18958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 49:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIC: 453136.8230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Estimate</th>\n",
              "      <th>Std Error</th>\n",
              "      <th>t-stat</th>\n",
              "      <th>p-Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intercept</td>\n",
              "      <td>75142.6520</td>\n",
              "      <td>81.3631</td>\n",
              "      <td>81.4747</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MIN_YEARS_EXPERIENCE</td>\n",
              "      <td>6629.0352</td>\n",
              "      <td>23.5386</td>\n",
              "      <td>-3.7848</td>\n",
              "      <td>0.0002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DURATION</td>\n",
              "      <td>-89.0893</td>\n",
              "      <td>2051.7917</td>\n",
              "      <td>0.3695</td>\n",
              "      <td>0.7118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EMPLOYMENT_TYPE_NAME_vec_Fulltime</td>\n",
              "      <td>758.1210</td>\n",
              "      <td>2611.3277</td>\n",
              "      <td>-2.5606</td>\n",
              "      <td>0.0105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EMPLOYMENT_TYPE_NAME_vec_Parttime</td>\n",
              "      <td>-6686.4509</td>\n",
              "      <td>2048.9189</td>\n",
              "      <td>5.2995</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Undefined</td>\n",
              "      <td>10858.3452</td>\n",
              "      <td>2105.9892</td>\n",
              "      <td>6.4966</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Remote</td>\n",
              "      <td>13681.8588</td>\n",
              "      <td>2544.8043</td>\n",
              "      <td>7.4017</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Hybrid</td>\n",
              "      <td>18835.8525</td>\n",
              "      <td>2786.7053</td>\n",
              "      <td>26.9647</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "\n",
        "feature_names = assembler.getInputCols()\n",
        "\n",
        "glr = GeneralizedLinearRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"SALARY\",\n",
        "    family=\"gaussian\", \n",
        "    link=\"identity\", \n",
        "    maxIter=10, \n",
        "    regParam=0.3 \n",
        ")\n",
        "# Train the GLR model using the training dataset to learn the relationship between features and SALARY\n",
        "glr_model = glr.fit(regression_train)\n",
        "summary = glr_model.summary\n",
        "\n",
        "# Coefficients and Intercept\n",
        "print(\"Intercept: {:.4f}\".format(glr_model.intercept))\n",
        "print(\"Coefficients:\")\n",
        "for i, coef in enumerate(glr_model.coefficients):\n",
        "    print(f\" Feature {i + 1}: {coef:.4f}\")\n",
        "    \n",
        "# Summary stats\n",
        "print(\"\\n--- Regression Summary ---\")\n",
        "print(\"Coefficient Standard Errors:\", [f\"{val:.4f}\" for val in summary.coefficientStandardErrors])\n",
        "print(\"T Values:\", [f\"{val:.4f}\" for val in summary.tValues])\n",
        "print(\"P Values:\", [f\"{val:.4f}\" for val in summary.pValues])\n",
        "\n",
        "# print(f\"\\nDispersion: {summary.dispersion:.4f}\")\n",
        "print(f\"Null Deviance: {summary.nullDeviance:.4f}\")\n",
        "print(f\"Residual DF Null: {summary.residualDegreeOfFreedomNull}\")\n",
        "print(f\"Deviance: {summary.deviance:.4f}\")\n",
        "print(f\"Residual DF: {summary.residualDegreeOfFreedom}\")\n",
        "print(f\"AIC: {summary.aic:.4f}\")\n",
        "\n",
        "# 1. Pull feature names directly from Java backend\n",
        "feature_names = summary._call_java(\"featureNames\")\n",
        "\n",
        "# 2. Construct full table including intercept\n",
        "features = [\"Intercept\"] + feature_names\n",
        "coefs = [glr_model.intercept] + list(glr_model.coefficients)\n",
        "se = list(summary.coefficientStandardErrors)\n",
        "tvals = list(summary.tValues)\n",
        "pvals = list(summary.pValues)\n",
        "\n",
        "#This block ensures all regression output values (coefficients, errors, t-values, p-values) \n",
        "\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "# print(\"Length of features:\", len(features))\n",
        "# print(\"Length of coefs:\", len(coefs))\n",
        "# print(\"Length of se:\", len(se))\n",
        "# print(\"Length of tvals:\", len(tvals))\n",
        "# print(\"Length of pvals:\", len(pvals))\n",
        "\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Estimate\": [f\"{v:.4f}\" if v is not None else None for v in coefs],\n",
        "    \"Std Error\": [f\"{v:.4f}\" if v is not None else None for v in se],\n",
        "    \"t-stat\": [f\"{v:.4f}\" if v is not None else None for v in tvals],\n",
        "    \"p-Value\": [f\"{v:.4f}\" if v is not None else None for v in pvals]\n",
        "})\n",
        "\n",
        "\n",
        "# 4. Save for report\n",
        "coef_table.to_csv(\"output/glr_summary.csv\", index=False)\n",
        "\n",
        "# 5. Optional pretty print\n",
        "HTML(coef_table.to_html())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Polymnomial Regression (5)\n",
        "- Train a Polynomial Linear Regression model using the training data.\n",
        "- Make sure to use the features_poly column from the assembled data frame to fit the model.\n",
        "- You will run in to an important issue here. Please make an effort in figuring it by yourself. This is one of the most asked interview questions in CapitalOne’s management recruiting program.\n",
        "- Evaluate the model on the test data.\n",
        "- Print the coefficients, intercept, R², RMSE, and MAE.\n",
        "- Use the summary object to extract the coefficients and their standard errors, t-values, and p-values.\n",
        "- Create a DataFrame to display the coefficients, standard errors, t-values, p-values, and confidence intervals.\n",
        "- Interpret the coefficients and their significance and explain the model performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------------------------------+\n",
            "|SALARY|features_poly                             |\n",
            "+------+------------------------------------------+\n",
            "|92962 |(10,[0,1,2,5,7],[2.0,4.0,18.0,1.0,1.0])   |\n",
            "|107645|(10,[0,1,2,5],[10.0,100.0,18.0,1.0])      |\n",
            "|192800|(10,[0,1,2,5,7],[6.0,36.0,55.0,1.0,1.0])  |\n",
            "|125900|(10,[0,1,2,5,7],[12.0,144.0,18.0,1.0,1.0])|\n",
            "|170000|(10,[0,1,2,5,7],[6.0,36.0,18.0,1.0,1.0])  |\n",
            "+------+------------------------------------------+\n",
            "only showing top 5 rows\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23697, 14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18966, 14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4731, 14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 62540.2223\n",
            "Coefficients:\n",
            " Feature 1: 12827.0612\n",
            " Feature 2: -459.0208\n",
            " Feature 3: -89.3853\n",
            " Feature 4: 4584.0005\n",
            " Feature 5: -2872.4972\n",
            " Feature 6: -1223.8212\n",
            " Feature 7: -7488.6018\n",
            " Feature 8: 10504.5657\n",
            " Feature 9: 13577.9007\n",
            " Feature 10: 18409.0468\n",
            "\n",
            "--- Regression Summary ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficient Standard Errors: ['291.9502', '20.7388', '23.2550', '4892.8155', '918.9098', '2030.2872', '2578.9448', '2022.9924', '2079.4914', '2512.8970', '2811.2254']\n",
            "T Values: ['43.9358', '-22.1334', '-3.8437', '0.9369', '-3.1260', '-0.6028', '-2.9037', '5.1926', '6.5294', '7.3258', '22.2466']\n",
            "P Values: ['0.0000', '0.0000', '0.0001', '0.3488', '0.0018', '0.5467', '0.0037', '0.0000', '0.0000', '0.0000', '0.0000']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null Deviance: 35794690345776.1094\n",
            "Residual DF Null: 18965\n",
            "Deviance: 25706616189569.7617\n",
            "Residual DF: 18955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 92:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIC: 452652.2063\n",
            "---This is Diagnostic check, No need to print it in the final doc---\n",
            "Length of features: 11\n",
            "Length of coefs: 11\n",
            "Length of se: 11\n",
            "Length of tvals: 11\n",
            "Length of pvals: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Estimate</th>\n",
              "      <th>Std Error</th>\n",
              "      <th>t-stat</th>\n",
              "      <th>p-Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intercept</td>\n",
              "      <td>62540.2223</td>\n",
              "      <td>291.9502</td>\n",
              "      <td>43.9358</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MIN_YEARS_EXPERIENCE</td>\n",
              "      <td>12827.0612</td>\n",
              "      <td>20.7388</td>\n",
              "      <td>-22.1334</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MIN_YEARS_EXPERIENCE_SQ</td>\n",
              "      <td>-459.0208</td>\n",
              "      <td>23.2550</td>\n",
              "      <td>-3.8437</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DURATION</td>\n",
              "      <td>-89.3853</td>\n",
              "      <td>4892.8155</td>\n",
              "      <td>0.9369</td>\n",
              "      <td>0.3488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IS_INTERNSHIP</td>\n",
              "      <td>4584.0005</td>\n",
              "      <td>918.9098</td>\n",
              "      <td>-3.1260</td>\n",
              "      <td>0.0018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>COMPANY_IS_STAFFING</td>\n",
              "      <td>-2872.4972</td>\n",
              "      <td>2030.2872</td>\n",
              "      <td>-0.6028</td>\n",
              "      <td>0.5467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>EMPLOYMENT_TYPE_NAME_vec_Fulltime</td>\n",
              "      <td>-1223.8212</td>\n",
              "      <td>2578.9448</td>\n",
              "      <td>-2.9037</td>\n",
              "      <td>0.0037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>EMPLOYMENT_TYPE_NAME_vec_Parttime</td>\n",
              "      <td>-7488.6018</td>\n",
              "      <td>2022.9924</td>\n",
              "      <td>5.1926</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Undefined</td>\n",
              "      <td>10504.5657</td>\n",
              "      <td>2079.4914</td>\n",
              "      <td>6.5294</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Remote</td>\n",
              "      <td>13577.9007</td>\n",
              "      <td>2512.8970</td>\n",
              "      <td>7.3258</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>REMOTE_TYPE_NAME_vec_Hybrid</td>\n",
              "      <td>18409.0468</td>\n",
              "      <td>2811.2254</td>\n",
              "      <td>22.2466</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.sql.functions import pow, col\n",
        "\n",
        "# Create squared term for Polynomial Regression\n",
        "regression_data_poly = regression_data.withColumn(\"MIN_YEARS_EXPERIENCE_SQ\", pow(col(\"MIN_YEARS_EXPERIENCE\"), 2))\n",
        "\n",
        "# Assemble polynomial features\n",
        "assembler_poly = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"MIN_YEARS_EXPERIENCE\", \"MIN_YEARS_EXPERIENCE_SQ\",\n",
        "        \"DURATION\", \"IS_INTERNSHIP\", \"COMPANY_IS_STAFFING\"\n",
        "    ] + [f\"{col}_vec\" for col in categorical_cols],\n",
        "    outputCol=\"features_poly\"\n",
        ")\n",
        "\n",
        "regression_data_poly_final=assembler_poly.transform(regression_data_poly)\n",
        "#show final structure\n",
        "regression_data_poly_final.select(\"SALARY\",  \"features_poly\").show(5, truncate=False)\n",
        "\n",
        "\n",
        "# Split Data\n",
        "polyreg_train, polyreg_test = regression_data_poly_final.randomSplit([0.8, 0.2], seed=42)\n",
        "print((regression_data_poly_final.count(), len(regression_data_poly_final.columns)))\n",
        "print((polyreg_train.count(), len(polyreg_train.columns)))\n",
        "print((polyreg_test.count(), len(polyreg_test.columns)))\n",
        "\n",
        "\n",
        "feature_names = assembler_poly.getInputCols()\n",
        "\n",
        "poly_glr_min_years = GeneralizedLinearRegression(\n",
        "    featuresCol=\"features_poly\",\n",
        "    labelCol=\"SALARY\",\n",
        "    family=\"gaussian\", \n",
        "    link=\"identity\",\n",
        "    maxIter=10, \n",
        "    regParam=0.3 \n",
        ")\n",
        "\n",
        "poly_glr_min_years_model = poly_glr_min_years.fit(polyreg_train)\n",
        "poly_summary = poly_glr_min_years_model.summary\n",
        "\n",
        "\n",
        "\n",
        "#**************************************************************************************************************\n",
        "\n",
        "# Coefficients and Intercept\n",
        "print(\"Intercept: {:.4f}\".format(poly_glr_min_years_model.intercept))\n",
        "print(\"Coefficients:\")\n",
        "for i, coef in enumerate(poly_glr_min_years_model.coefficients):\n",
        "    print(f\" Feature {i + 1}: {coef:.4f}\")\n",
        "    \n",
        "# Summary stats\n",
        "print(\"\\n--- Regression Summary ---\")\n",
        "print(\"Coefficient Standard Errors:\", [f\"{val:.4f}\" for val in poly_summary.coefficientStandardErrors])\n",
        "print(\"T Values:\", [f\"{val:.4f}\" for val in poly_summary.tValues])\n",
        "print(\"P Values:\", [f\"{val:.4f}\" for val in poly_summary.pValues])\n",
        "\n",
        "# print(f\"\\nDispersion: {summary.dispersion:.4f}\")\n",
        "print(f\"Null Deviance: {poly_summary.nullDeviance:.4f}\")\n",
        "print(f\"Residual DF Null: {poly_summary.residualDegreeOfFreedomNull}\")\n",
        "print(f\"Deviance: {poly_summary.deviance:.4f}\")\n",
        "print(f\"Residual DF: {poly_summary.residualDegreeOfFreedom}\")\n",
        "print(f\"AIC: {poly_summary.aic:.4f}\")\n",
        "\n",
        "# 1. Pull feature names directly from Java backend\n",
        "feature_names = poly_summary._call_java(\"featureNames\")\n",
        "\n",
        "# 2. Construct full table including intercept\n",
        "features = [\"Intercept\"] + feature_names\n",
        "coefs = [poly_glr_min_years_model.intercept] + list(poly_glr_min_years_model.coefficients)\n",
        "se = list(poly_summary.coefficientStandardErrors)\n",
        "tvals = list(poly_summary.tValues)\n",
        "pvals = list(poly_summary.pValues)\n",
        "\n",
        "#This block ensures all regression output values (coefficients, errors, t-values, p-values) \n",
        "\n",
        "print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "print(\"Length of features:\", len(features))\n",
        "print(\"Length of coefs:\", len(coefs))\n",
        "print(\"Length of se:\", len(se))\n",
        "print(\"Length of tvals:\", len(tvals))\n",
        "print(\"Length of pvals:\", len(pvals))\n",
        "\n",
        "\n",
        "coef_table = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Estimate\": [f\"{v:.4f}\" if v is not None else None for v in coefs],\n",
        "    \"Std Error\": [f\"{v:.4f}\" if v is not None else None for v in se],\n",
        "    \"t-stat\": [f\"{v:.4f}\" if v is not None else None for v in tvals],\n",
        "    \"p-Value\": [f\"{v:.4f}\" if v is not None else None for v in pvals]\n",
        "})\n",
        "\n",
        "\n",
        "# 4. Save for report\n",
        "coef_table.to_csv(\"output/poly_summary.csv\", index=False)\n",
        "\n",
        "# 5. Optional pretty print\n",
        "HTML(coef_table.to_html())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest Regressor (6)\n",
        "- Train a Random Forest Regressor model using the training data.\n",
        "- Make sure to use the features column from the assembled data frame to fit the model.\n",
        "- choose anywhere between 100-500 trees for the model.\n",
        "- choose max depth between 4-10.\n",
        "- remembernumber of trees and max depth are hyperparameters and roughly inversely proportional to each other.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "data_rf = regression_data_final"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
